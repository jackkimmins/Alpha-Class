{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Define data augmentation\n",
    "data_augmentation = Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.3),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# Load the EMNIST dataset\n",
    "builder = tfds.builder('emnist/byclass')\n",
    "builder.download_and_prepare()\n",
    "datasets = builder.as_dataset(as_supervised=True)\n",
    "train_dataset, test_dataset = datasets['train'], datasets['test']\n",
    "\n",
    "# Updated preprocessing function to normalize, reshape, and correct the orientation of images\n",
    "def preprocess(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.image.rot90(img, k=-1)\n",
    "    img = tf.image.flip_left_right(img)\n",
    "    img = tf.expand_dims(img, -1)\n",
    "    return img, label\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "test_dataset = test_dataset.map(preprocess)\n",
    "\n",
    "# Batch and prefetch the dataset for performance\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Model definition with data augmentation\n",
    "model = models.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28, 1)),\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Generate a plot of the model architecture-\n",
    "plot_model(model, to_file='web/img/model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput the number of images in the training set\n",
    "print(\"Number of training images: \", builder.info.splits['train'].num_examples)\n",
    "print(\"Number of test images: \", builder.info.splits['test'].num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=20,\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/emnist_cnn_savedmodel')\n",
    "\n",
    "!tensorflowjs_converter --input_format=tf_saved_model --output_node_names='softmax_tensor' models/emnist_cnn_savedmodel web/models/emnist_cnn_tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the image file\n",
    "# image_path = '4.png'\n",
    "# image_string = tf.io.read_file(image_path)\n",
    "\n",
    "# # Decode the image, convert it to grayscale, and resize it\n",
    "# img = tf.image.decode_image(image_string, channels=1)\n",
    "# img = tf.image.resize(img, [28, 28])\n",
    "\n",
    "# # Normalize the pixel values\n",
    "# img_array = img / 255.0\n",
    "\n",
    "# # Expand dimensions to fit the model input shape (1, 28, 28, 1)\n",
    "# img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# # Make a prediction\n",
    "# predictions = model.predict(img_array)\n",
    "\n",
    "# # Get the predicted label\n",
    "# predicted_label = np.argmax(predictions)\n",
    "\n",
    "# print(f'Predicted label: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jide-python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
