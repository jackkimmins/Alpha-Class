{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " data_augmentation (Sequent  (None, 28, 28, 1)         0         \n",
      " ial)                                                            \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_29 (Ba  (None, 26, 26, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 12, 12, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_30 (Ba  (None, 10, 10, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 4, 4, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 4, 4, 64)          0         \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 2, 2, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_31 (Ba  (None, 2, 2, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 62)                15934     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 287006 (1.09 MB)\n",
      "Trainable params: 286558 (1.09 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define data augmentation\n",
    "data_augmentation = Sequential([\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.3),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    layers.experimental.preprocessing.RandomTranslation(height_factor=0.2, width_factor=0.2),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# Load the EMNIST dataset\n",
    "builder = tfds.builder('emnist/byclass')\n",
    "builder.download_and_prepare()\n",
    "datasets = builder.as_dataset(as_supervised=True)\n",
    "train_dataset, test_dataset = datasets['train'], datasets['test']\n",
    "\n",
    "# Updated preprocessing function to normalize, reshape, and correct the orientation of images\n",
    "def preprocess(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.image.rot90(img, k=-1)\n",
    "    img = tf.image.flip_left_right(img)\n",
    "    img = tf.expand_dims(img, -1)\n",
    "    return img, label\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "train_dataset = train_dataset.map(preprocess)\n",
    "test_dataset = test_dataset.map(preprocess)\n",
    "\n",
    "# Batch and prefetch the dataset for performance\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Model definition with data augmentation\n",
    "model = models.Sequential([\n",
    "    tf.keras.Input(shape=(28, 28, 1)),\n",
    "    data_augmentation,\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(62, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Generate a plot of the model architecture-\n",
    "plot_model(model, to_file='web/img/model.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouput the number of images in the training set\n",
    "print(\"Number of training images: \", builder.info.splits['train'].num_examples)\n",
    "print(\"Number of test images: \", builder.info.splits['test'].num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=20,\n",
    "                    validation_data=test_dataset,\n",
    "                    callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'\\nTest accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/emnist_cnn_savedmodel')\n",
    "\n",
    "!tensorflowjs_converter --input_format=tf_saved_model --output_node_names='softmax_tensor' models/emnist_cnn_savedmodel web/models/emnist_cnn_tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the image file\n",
    "# image_path = '4.png'\n",
    "# image_string = tf.io.read_file(image_path)\n",
    "\n",
    "# # Decode the image, convert it to grayscale, and resize it\n",
    "# img = tf.image.decode_image(image_string, channels=1)\n",
    "# img = tf.image.resize(img, [28, 28])\n",
    "\n",
    "# # Normalize the pixel values\n",
    "# img_array = img / 255.0\n",
    "\n",
    "# # Expand dimensions to fit the model input shape (1, 28, 28, 1)\n",
    "# img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# # Make a prediction\n",
    "# predictions = model.predict(img_array)\n",
    "\n",
    "# # Get the predicted label\n",
    "# predicted_label = np.argmax(predictions)\n",
    "\n",
    "# print(f'Predicted label: {predicted_label}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jide-python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
